{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential, load_model, Model\n",
    "from tensorflow.keras.layers import Conv2D,GlobalAveragePooling2D,Dense,Softmax,Flatten,MaxPooling2D,Dropout,Activation, Lambda, concatenate,BatchNormalization\n",
    "from keras.datasets import cifar100, cifar10\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.losses import kullback_leibler_divergence\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.metrics import categorical_accuracy\n",
    "from keras import regularizers\n",
    "from keras import optimizers\n",
    "from keras import backend as K\n",
    "import torch\n",
    "import gc\n",
    "#import seaborn as sns\n",
    "import h5py\n",
    "import sys\n",
    "\n",
    "#import os\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Dropout, Input, Add, BatchNormalization, Activation\n",
    "from keras.activations import relu, softmax\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import plot_model\n",
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train_100: (50000, 32, 32, 3)     y_train_fine: (50000, 100)     y_train_coarse: (50000, 20)\n",
      "x_test_100: (10000, 32, 32, 3)       y_test_fine: (10000, 100)       y_test_coarse: (10000, 20)\n"
     ]
    }
   ],
   "source": [
    "# Cifar100\n",
    "\n",
    "num_classes_fine = 100\n",
    "num_classes_coarse= 20\n",
    "(x_train_100, y_train_f), (x_test_100, y_test_f) = cifar100.load_data()\n",
    "(x_train_100, y_train_coarse), (x_test_100, y_test_coarse) = cifar100.load_data(label_mode='coarse')\n",
    "\n",
    "#x_train_100= x_train_100[:30000]\n",
    "#y_train_f= y_train_f[:30000]\n",
    "\n",
    "\n",
    "\n",
    "x_train_100 = x_train_100.astype('float32')\n",
    "x_test_100 = x_test_100.astype('float32')\n",
    "\n",
    "y_train_fine = to_categorical(y_train_f, num_classes_fine)\n",
    "y_test_fine = to_categorical(y_test_f, num_classes_fine)\n",
    "y_train_coarse = to_categorical(y_train_coarse, num_classes_coarse)\n",
    "y_test_coarse = to_categorical(y_test_coarse, num_classes_coarse)\n",
    "\n",
    "\n",
    "def normalize(X_train,X_test):\n",
    "    mean = np.mean(X_train,axis=(0,1,2,3))\n",
    "    std = np.std(X_train, axis=(0, 1, 2, 3))\n",
    "    X_train = (X_train-mean)/(std+1e-7)\n",
    "    X_test = (X_test-mean)/(std+1e-7)\n",
    "    return X_train, X_test\n",
    "\n",
    "\n",
    "x_train_100, x_test_100 = normalize(x_train_100, x_test_100)\n",
    "\n",
    "print(f'x_train_100: {x_train_100.shape}     y_train_fine: {y_train_fine.shape}     y_train_coarse: {y_train_coarse.shape}')\n",
    "print(f'x_test_100: {x_test_100.shape}       y_test_fine: {y_test_fine.shape}       y_test_coarse: {y_test_coarse.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def teacher_skip_connection_model(num_classes):\n",
    "\n",
    "    global Temperature, sgd, y_true, y_pred\n",
    "\n",
    "    input_residual= Input(shape=(32,32,3))\n",
    "    residual= Conv2D(128,(4,4), strides=(4,4), padding='valid', activation='relu', kernel_regularizer=regularizers.l2(0.0005))(input_residual)\n",
    "    \n",
    "    input= Input(shape=(8,8,128))\n",
    "    teacher= Add()([residual, input])\n",
    "\n",
    "    teacher= Conv2D(256,(3,3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.0005))(teacher)\n",
    "    teacher=BatchNormalization()(teacher)\n",
    "    teacher=Dropout(0.4)(teacher)\n",
    "\n",
    "    teacher= Conv2D(256,(3,3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.0005))(teacher)\n",
    "    teacher=BatchNormalization()(teacher)\n",
    "    teacher=Dropout(0.4)(teacher)\n",
    "\n",
    "    teacher=Conv2D(256,(3,3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.0005))(teacher)\n",
    "    teacher=BatchNormalization()(teacher)\n",
    "\n",
    "    teacher=MaxPooling2D(pool_size=(2,2))(teacher)\n",
    "\n",
    "    teacher=Conv2D(512,(3,3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.0005))(teacher)\n",
    "    teacher=BatchNormalization()(teacher)\n",
    "    teacher=Dropout(0.4)(teacher)\n",
    "\n",
    "    teacher=Conv2D(512,(3,3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.0005))(teacher)\n",
    "    teacher=BatchNormalization()(teacher)\n",
    "    teacher=Dropout(0.4)(teacher)\n",
    "\n",
    "    teacher=Conv2D(512,(3,3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.0005))(teacher)\n",
    "    teacher=BatchNormalization()(teacher)\n",
    "\n",
    "\n",
    "    teacher=MaxPooling2D(pool_size=(2,2))(teacher)\n",
    "\n",
    "    teacher= Conv2D(512,(3,3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.0005))(teacher)\n",
    "    teacher= BatchNormalization()(teacher)\n",
    "    teacher= Dropout(0.4)(teacher)\n",
    "\n",
    "    teacher= Conv2D(512,(3,3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.0005))(teacher)\n",
    "    teacher= BatchNormalization()(teacher)\n",
    "    teacher= Dropout(0.4)(teacher)\n",
    "\n",
    "    teacher= Conv2D(512,(3,3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.0005))(teacher)\n",
    "    teacher= BatchNormalization()(teacher)\n",
    "\n",
    "    teacher= MaxPooling2D(pool_size=(2,2))(teacher)\n",
    "    teacher= Dropout(0.5)(teacher)\n",
    " \n",
    "    teacher= Flatten()(teacher)\n",
    "    teacher= Dense(512, kernel_regularizer=regularizers.l2(0.0005))(teacher)\n",
    "    teacher= Activation('relu')(teacher)\n",
    "    teacher= BatchNormalization()(teacher)\n",
    "    teacher= Dropout(0.5)(teacher)\n",
    "\n",
    "    teacher= Dense(num_classes)(teacher)\n",
    "    #teacher= Activation('softmax')(teacher)\n",
    "    \n",
    "    teacher= Model([input,input_residual], teacher)\n",
    "\n",
    "    logits= teacher.layers[37].output\n",
    "    probs= Activation('softmax')(logits)\n",
    "    logits_T= Lambda(lambda x:x/Temperature)(logits)\n",
    "    probs_T= Activation('softmax')(logits_T)\n",
    "\n",
    "    CombinedLayers= concatenate([probs, probs_T])\n",
    "    teacher= Model(teacher.input, CombinedLayers)\n",
    "\n",
    "    teacher.compile(optimizer=sgd, loss=lambda y_true,y_pred: teacher_loss(y_true, y_pred), metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    return teacher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def student_model(num_classes):\n",
    "    \n",
    "    global sgd, y_true, y_pred, Temperature, Alpha\n",
    "    student= Sequential()\n",
    "\n",
    "    student.add(Conv2D(64,(3,3), padding='same', activation='relu',kernel_regularizer=regularizers.l2(0.0005), input_shape=(32,32,3)))\n",
    "    student.add(BatchNormalization())\n",
    "    student.add(Dropout(0.3))\n",
    "\n",
    "    student.add(Conv2D(64,(3,3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    student.add(BatchNormalization()) \n",
    "\n",
    "    student.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "    student.add(Conv2D(128,(3,3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    student.add(BatchNormalization())\n",
    "    student.add(Dropout(0.4))\n",
    "\n",
    "    student.add(Conv2D(128,(3,3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    student.add(BatchNormalization())\n",
    "\n",
    "    student.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "    #student.add(Conv2D(256,(3,3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.0005), input_shape= (8,8,128)))\n",
    "    #student.add(BatchNormalization())\n",
    "    #student.add(Dropout(0.4))\n",
    "\n",
    "    #student.add(Conv2D(256,(3,3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    #student.add(BatchNormalization())\n",
    "    #student.add(Dropout(0.4))\n",
    "\n",
    "    #student.add(Conv2D(256,(3,3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    #student.add(BatchNormalization()) \n",
    "\n",
    "    #student.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "    student.add(Flatten())\n",
    "    student.add(Dense(512, kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    student.add(Activation('relu'))\n",
    "    student.add(BatchNormalization())\n",
    "    student.add(Dropout(0.5))\n",
    "\n",
    "    student.add(Dense(num_classes))\n",
    "    #student.add(Activation('softmax'))\n",
    " \n",
    "    student_logits= student.layers[17].output  \n",
    "    probs= Activation('softmax')(student_logits)                     # hard prediction\n",
    "    logits_T= Lambda(lambda x:x/Temperature)(student_logits)         #z/T\n",
    "    probs_T= Activation('softmax')(logits_T)                         # soft prediction\n",
    "\n",
    "    CombinedLayers= concatenate([probs, probs_T])\n",
    "    student= Model(student.input, CombinedLayers)\n",
    "    student.compile(optimizer=sgd, loss=lambda y_true,y_pred: student_loss(y_true, y_pred, alpha=Alpha, T=Temperature), metrics=['accuracy'])\n",
    "\n",
    "    return student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def teacher_loss(y_true, y_pred):\n",
    "    global count, num_classes_t, pred_sum, pred_avg, batchsize\n",
    "    y_true, y_true_soft= y_true[:,:num_classes_t], y_true[:, num_classes_t:]\n",
    "    y_pred, y_pred_soft= y_pred[:,:num_classes_t], y_pred[:, num_classes_t:]\n",
    "\n",
    "    #(y_pred,y_pred_soft) = tf.split(y_pred,num_or_size_splits = 2, axis = 1)\n",
    "    #(y_true,y_true_soft) = tf.split(y_true,num_or_size_splits = 2, axis = 1)\n",
    "\n",
    "    loss= keras.losses.CategoricalCrossentropy(reduction=tf.keras.losses.Reduction.AUTO, from_logits=False)(y_true,y_pred)\n",
    "\n",
    "    y_pred_soft_np=K.eval(y_pred_soft)\n",
    "    y_true_np= K.eval(y_true)\n",
    " \n",
    "    for i in range(y_pred_soft_np.shape[0]):  #(128,100)\n",
    "        label= np.argmax(y_true_np[i])    \n",
    "        pred_sum[label]= pred_sum[label] + y_pred_soft_np[i]\n",
    "        count[label]= count[label]+1\n",
    "        #print('\\\\ni: ', i)\n",
    "        #print('label: ',label)\n",
    "        #print('true_soft argmax: ', np.argmax(y_true_soft_np[i]))   \n",
    "        #print('hard prediction for the batch: ', np.argmax(y_pred_np[i]))  \n",
    "        #print('pred_sum[label] argmax: ', np.argmax(pred_sum[label]))\n",
    "        #print('pred argmax > pred label?: ', np.argmax(y_pred_soft_np[i])>y_pred_soft_np[i,label])\n",
    " \n",
    " \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def student_loss(y_true, y_pred, alpha, T):\n",
    "    global num_classes_s\n",
    "    y_true, y_true_soft= y_true[:,:num_classes_s], y_true[:, num_classes_s:]\n",
    "    y_pred, y_pred_soft= y_pred[:,:num_classes_s], y_pred[:, num_classes_s:]\n",
    "    \n",
    "    #cross-entropy loss (temperatureX)\n",
    "    #CE_loss = categorical_crossentropy(y_true,y_pred)\n",
    "    CE_loss= keras.losses.CategoricalCrossentropy(reduction=tf.keras.losses.Reduction.AUTO, from_logits=False)(y_true,y_pred)\n",
    "    \n",
    "    #KL-divergence loss (temperatureO)\n",
    "    KL_loss = (T**2)*(kullback_leibler_divergence(y_true_soft, y_pred_soft))\n",
    "    \n",
    "    loss= alpha*CE_loss + (1-alpha)*KL_loss\n",
    "    print(loss)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distillation(student_epoch, teacher_epoch, iteration, batch_size, alpha, temperature):\n",
    "    global count, Temperature, Alpha, pred_sum, pred_avg, sgd, num_classes_s, num_classes_t, batchsize\n",
    "    \n",
    "    s_d_val_loss = np.empty(student_epoch*iteration)\n",
    "    s_d_val_acc = np.empty(student_epoch*iteration)\n",
    "    t_d_val_loss = np.empty(teacher_epoch*iteration)\n",
    "    t_d_val_acc = np.empty(teacher_epoch*iteration)\n",
    "       \n",
    "    #params\n",
    "    Temperature= temperature\n",
    "    #Alpha= alpha\n",
    "    num_classes_s = num_classes_fine\n",
    "    num_classes_t= num_classes_fine\n",
    "    lr= 0.1\n",
    "    lr_decay= 1e-6\n",
    "    batchsize=batch_size\n",
    "    weight_decay= 0.0005\n",
    "    lr_drop=20\n",
    "    pred_avg=np.zeros(num_classes_t) \n",
    "    \n",
    "        \n",
    "    #models\n",
    "    sgd= optimizers.SGD(learning_rate= lr, decay= lr_decay, momentum=0.9, nesterov=True)\n",
    "    teacher= teacher_skip_connection_model(num_classes_t)\n",
    "    student= student_model(num_classes_s)\n",
    "      \n",
    "    \n",
    "    for i in range(iteration):\n",
    "     \n",
    "        #student training\n",
    "        print(f'student {i+1}th training')\n",
    "        if i<2:   #한번은 update 되고 distill 받게(2)\n",
    "            Alpha=1\n",
    "        else:\n",
    "            Alpha= alpha\n",
    "              \n",
    "        def lr_scheduler(student_epoch):\n",
    "            return lr * (0.5 ** (student_epoch // lr_drop))\n",
    "        reduce_lr = keras.callbacks.LearningRateScheduler(lr_scheduler)\n",
    "\n",
    "        y_train_soft= np.zeros((50000,num_classes_t))\n",
    "        for index in range(50000):\n",
    "            label= np.argmax(y_train_fine[index])\n",
    "            y_train_soft[index]= pred_avg[label]\n",
    "        y_train_new= np.c_[y_train_fine, y_train_soft]\n",
    "           \n",
    "        history_s= student.fit(x_train_100, y_train_new, batch_size=batchsize,\n",
    "                               epochs= student_epoch, callbacks=[reduce_lr],\n",
    "                               validation_split=0.2, shuffle=False, verbose=2)\n",
    "         \n",
    "        for e in range(student_epoch):\n",
    "            s_d_val_loss[i*student_epoch +e]= history_s.history['val_loss'][e]\n",
    "            s_d_val_acc[i*student_epoch +e]= history_s.history['val_accuracy'][e]\n",
    "          \n",
    "\n",
    "\n",
    "\n",
    "        #teacher training\n",
    "        count=np.zeros(num_classes_t, dtype=np.int)\n",
    "        pred_sum=np.zeros((num_classes_t, num_classes_t))\n",
    "        pred_avg=np.zeros((num_classes_t, num_classes_t))  #initialize\n",
    "     \n",
    "        def lr_scheduler(teacher_epoch):\n",
    "            return lr * (0.5 ** (teacher_epoch // lr_drop))\n",
    "        reduce_lr = keras.callbacks.LearningRateScheduler(lr_scheduler)\n",
    "            \n",
    "        out_s= Model(inputs= student.input, outputs= student.layers[12].output)\n",
    "        s_output= out_s.predict(x_train_100, batch_size=2)\n",
    "        y_train_new= np.c_[y_train_fine, y_train_fine]\n",
    "            \n",
    "        print(f'teacher {i+1}th training')\n",
    "        history_t= teacher.fit([s_output, x_train_100], y_train_new, batch_size= batchsize,\n",
    "                               epochs= teacher_epoch, callbacks=[reduce_lr],\n",
    "                               validation_split=0.2, shuffle=False, verbose=2)\n",
    "        \n",
    "            \n",
    "        #바로 직전 iter의 pred만 student한테 줄때 이 loop안에서 초기화\n",
    "        for classes in range(num_classes_t):\n",
    "             pred_avg[classes]= pred_sum[classes]/count[classes]\n",
    "        '''\n",
    "        #학습 된 후 output뽑아서 label별 평균\n",
    "        output= history_t.predict(s_output, batch_size=2)\n",
    "        for classes in range(num_classes_t):\n",
    "            label= np.argmax(y_train_fine[classes])\n",
    "            pred_sum[label]= pred_sum[label]+ output[classes]\n",
    "            count[classes]= count[classes]+1\n",
    "        pred_avg[classes]=\n",
    "        #loss바꿔야돼\n",
    "        '''\n",
    "            \n",
    "        #모든걸 누적. count 로 나누면 안됌 이전에 count 랑 다시 곱한다음에 pred_sum 또 추출해서 더하든지\n",
    "        \n",
    "        for e in range(teacher_epoch):\n",
    "            t_d_val_loss[i*teacher_epoch +e]= history_t.history['val_loss'][e]\n",
    "            t_d_val_acc[i*teacher_epoch +e]= history_t.history['val_accuracy'][e]\n",
    "                \n",
    "    return student, teacher, s_d_val_loss, s_d_val_acc, t_d_val_loss, t_d_val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student 1th training\n",
      "Epoch 1/5\n",
      "tf.Tensor(\n",
      "[6.1752005 6.1752005 6.1752005 6.1752005 6.1752005 6.1752005 6.1752005\n",
      " 6.1752005 6.1752005 6.1752005 6.1752005 6.1752005 6.1752005 6.1752005\n",
      " 6.1752005 6.1752005 6.1752005 6.1752005 6.1752005 6.1752005 6.1752005\n",
      " 6.1752005 6.1752005 6.1752005 6.1752005 6.1752005 6.1752005 6.1752005\n",
      " 6.1752005 6.1752005 6.1752005 6.1752005 6.1752005 6.1752005 6.1752005\n",
      " 6.1752005 6.1752005 6.1752005 6.1752005 6.1752005 6.1752005 6.1752005\n",
      " 6.1752005 6.1752005 6.1752005 6.1752005 6.1752005 6.1752005 6.1752005\n",
      " 6.1752005 6.1752005 6.1752005 6.1752005 6.1752005 6.1752005 6.1752005\n",
      " 6.1752005 6.1752005 6.1752005 6.1752005 6.1752005 6.1752005 6.1752005\n",
      " 6.1752005 6.1752005 6.1752005 6.1752005 6.1752005 6.1752005 6.1752005\n",
      " 6.1752005 6.1752005 6.1752005 6.1752005 6.1752005 6.1752005 6.1752005\n",
      " 6.1752005 6.1752005 6.1752005 6.1752005 6.1752005 6.1752005 6.1752005\n",
      " 6.1752005 6.1752005 6.1752005 6.1752005 6.1752005 6.1752005 6.1752005\n",
      " 6.1752005 6.1752005 6.1752005 6.1752005 6.1752005 6.1752005 6.1752005\n",
      " 6.1752005 6.1752005 6.1752005 6.1752005 6.1752005 6.1752005 6.1752005\n",
      " 6.1752005 6.1752005 6.1752005 6.1752005 6.1752005 6.1752005 6.1752005\n",
      " 6.1752005 6.1752005 6.1752005 6.1752005 6.1752005 6.1752005 6.1752005\n",
      " 6.1752005 6.1752005 6.1752005 6.1752005 6.1752005 6.1752005 6.1752005\n",
      " 6.1752005 6.1752005], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[5.964298 5.964298 5.964298 5.964298 5.964298 5.964298 5.964298 5.964298\n",
      " 5.964298 5.964298 5.964298 5.964298 5.964298 5.964298 5.964298 5.964298\n",
      " 5.964298 5.964298 5.964298 5.964298 5.964298 5.964298 5.964298 5.964298\n",
      " 5.964298 5.964298 5.964298 5.964298 5.964298 5.964298 5.964298 5.964298\n",
      " 5.964298 5.964298 5.964298 5.964298 5.964298 5.964298 5.964298 5.964298\n",
      " 5.964298 5.964298 5.964298 5.964298 5.964298 5.964298 5.964298 5.964298\n",
      " 5.964298 5.964298 5.964298 5.964298 5.964298 5.964298 5.964298 5.964298\n",
      " 5.964298 5.964298 5.964298 5.964298 5.964298 5.964298 5.964298 5.964298\n",
      " 5.964298 5.964298 5.964298 5.964298 5.964298 5.964298 5.964298 5.964298\n",
      " 5.964298 5.964298 5.964298 5.964298 5.964298 5.964298 5.964298 5.964298\n",
      " 5.964298 5.964298 5.964298 5.964298 5.964298 5.964298 5.964298 5.964298\n",
      " 5.964298 5.964298 5.964298 5.964298 5.964298 5.964298 5.964298 5.964298\n",
      " 5.964298 5.964298 5.964298 5.964298 5.964298 5.964298 5.964298 5.964298\n",
      " 5.964298 5.964298 5.964298 5.964298 5.964298 5.964298 5.964298 5.964298\n",
      " 5.964298 5.964298 5.964298 5.964298 5.964298 5.964298 5.964298 5.964298\n",
      " 5.964298 5.964298 5.964298 5.964298 5.964298 5.964298 5.964298 5.964298], shape=(128,), dtype=float32)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-a049f160d84b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mAlpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.6\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mTemperature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mstudent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mteacher\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms_d_val_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms_d_val_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt_d_val_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt_d_val_acc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdistillation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstudent_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mteacher_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatchsize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAlpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTemperature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-10-460d96a33219>\u001b[0m in \u001b[0;36mdistillation\u001b[1;34m(student_epoch, teacher_epoch, iteration, batch_size, alpha, temperature)\u001b[0m\n\u001b[0;32m     47\u001b[0m         history_s= student.fit(x_train_100, y_train_new, batch_size=batchsize,\n\u001b[0;32m     48\u001b[0m                                \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mstudent_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mreduce_lr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m                                validation_split=0.2, shuffle=False, verbose=2)\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstudent_epoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\hlnam\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1133\u001b[0m                 _r=1):\n\u001b[0;32m   1134\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1135\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1136\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\hlnam\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    838\u001b[0m       \u001b[1;32mdef\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    839\u001b[0m         \u001b[1;34m\"\"\"Runs a training execution with one step.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 840\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mstep_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    841\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    842\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\hlnam\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mstep_function\u001b[1;34m(model, iterator)\u001b[0m\n\u001b[0;32m    828\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    829\u001b[0m       \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 830\u001b[1;33m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    831\u001b[0m       outputs = reduce_per_replica(\n\u001b[0;32m    832\u001b[0m           outputs, self.distribute_strategy, reduction='first')\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\hlnam\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1261\u001b[0m       fn = autograph.tf_convert(\n\u001b[0;32m   1262\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[1;32m-> 1263\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1265\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\hlnam\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   2733\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2734\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2735\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2736\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2737\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\hlnam\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   3422\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3423\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mReplicaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplica_id_in_sync_group\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3424\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3425\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3426\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\hlnam\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    575\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    576\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUNSPECIFIED\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 577\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    578\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\hlnam\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mrun_step\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    821\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    822\u001b[0m       \u001b[1;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 823\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    824\u001b[0m         \u001b[1;31m# Ensure counter is updated only if `train_step` succeeds.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    825\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_minimum_control_deps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\hlnam\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    791\u001b[0m           y, y_pred, sample_weight, regularization_losses=self.losses)\n\u001b[0;32m    792\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 793\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompiled_metrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    794\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    795\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\hlnam\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\compile_utils.py\u001b[0m in \u001b[0;36mupdate_state\u001b[1;34m(self, y_true, y_pred, sample_weight)\u001b[0m\n\u001b[0;32m    428\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmetric_obj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m           \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 430\u001b[1;33m         \u001b[0mmetric_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_p\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    431\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mweighted_metric_obj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mweighted_metric_objs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\hlnam\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\metrics_utils.py\u001b[0m in \u001b[0;36mdecorated\u001b[1;34m(metric_obj, *args, **kwargs)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph_context_for_symbolic_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m       \u001b[0mupdate_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupdate_state_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mupdate_op\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# update_op will be None in eager execution.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m       \u001b[0mmetric_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mupdate_op\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\hlnam\\lib\\site-packages\\tensorflow\\python\\keras\\metrics.py\u001b[0m in \u001b[0;36mupdate_state_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    177\u001b[0m         \u001b[0mcontrol_status\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m         \u001b[0mag_update_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj_update_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontrol_status\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 179\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mag_update_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    180\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdef_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFunction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\hlnam\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    670\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 672\u001b[1;33m           \u001b[1;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    673\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ag_error_metadata'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\hlnam\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    353\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mconversion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_in_allowlist_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Allowlisted %s: from cache'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 355\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    356\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\hlnam\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    481\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    482\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 483\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    484\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    485\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\hlnam\\lib\\site-packages\\tensorflow\\python\\keras\\metrics.py\u001b[0m in \u001b[0;36mupdate_state\u001b[1;34m(self, y_true, y_pred, sample_weight)\u001b[0m\n\u001b[0;32m    645\u001b[0m     \u001b[0mmatches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fn_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    646\u001b[0m     return super(MeanMetricWrapper, self).update_state(\n\u001b[1;32m--> 647\u001b[1;33m         matches, sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    648\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    649\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\hlnam\\lib\\site-packages\\tensorflow\\python\\keras\\metrics.py\u001b[0m in \u001b[0;36mupdate_state\u001b[1;34m(self, values, sample_weight)\u001b[0m\n\u001b[0;32m    415\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduction\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mmetrics_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mReduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWEIGHTED_MEAN\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 417\u001b[1;33m         \u001b[0mnum_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    418\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    419\u001b[0m         \u001b[0mnum_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\hlnam\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\hlnam\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mcast\u001b[1;34m(x, dtype, name)\u001b[0m\n\u001b[0;32m    948\u001b[0m       \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"x\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_dtype\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mbase_type\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 950\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbase_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    951\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_complex\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mbase_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_floating\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    952\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Casting complex to real discards imaginary part.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\hlnam\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mcast\u001b[1;34m(x, DstT, Truncate, name)\u001b[0m\n\u001b[0;32m   1872\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1873\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[1;32m-> 1874\u001b[1;33m         _ctx, \"Cast\", name, x, \"DstT\", DstT, \"Truncate\", Truncate)\n\u001b[0m\u001b[0;32m   1875\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1876\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "student_epoch=5\n",
    "teacher_epoch=20\n",
    "iteration=10\n",
    "batchsize=128 \n",
    "Alpha=0.6\n",
    "Temperature=4\n",
    "student, teacher, s_d_val_loss, s_d_val_acc, t_d_val_loss, t_d_val_acc=distillation(student_epoch, teacher_epoch, iteration, batchsize, Alpha, Temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_len= np.arange(200)\n",
    "empty= np.zeros(150)\n",
    "empty[:]=np.NaN\n",
    "s_d_val_acc_2= np.hstack([s_d_val_acc,empty])\n",
    "\n",
    "np.save('meta_skipconn_student.npy', s_d_val_acc_2)\n",
    "np.save('meta_skipconn_teacher.npy', t_d_val_acc)\n",
    "plt.plot(x_len, meta_student, '-', color='red', label='meta distill_student')\n",
    "plt.plot(x_len, meta_teacher, '-', color='blue', label='meta distill_teacher')\n",
    "\n",
    "plt.plot(x_len, t_d_val_acc, '-', label='teacher')\n",
    "plt.plot(x_len, s_d_val_acc_2, '-', label='student')\n",
    "plt.ylim(0,0.6)\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training 되고 output에서 뽑아서 해보자"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
